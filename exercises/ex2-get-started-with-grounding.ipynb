{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5001f602",
   "metadata": {},
   "source": [
    "# Exercise 2 - Get Started with Grounding\n",
    "\n",
    "In this exercise, we'll start exploring the grounding on SAP AI Core. Grounding allows Large Language Models (LLMs) to reference specific knowledge sources when generating responses, which can help improve accuracy and relevance. \n",
    "\n",
    "We'll start with the basics by grounding an LLM using SAP.help as our knowledge source. \n",
    "\n",
    "This exercise will cover:\n",
    "\n",
    "* Basic grounding concepts in SAP AI Core\n",
    "* How to set up grounding with a sap.help.com\n",
    "* Comparing responses with and without grounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306eb73",
   "metadata": {},
   "source": [
    "## Check your connection to AI Core \n",
    "üëÄ  In the ```TECHE2025-167/excercise/init_env.py``` the values from ```TECHED2025-AI167/.aicore-config.json``` are assigned to environmental variables. That way the **SAP Cloud SDK for AI(Python)** will connect to AI Core. \n",
    "\n",
    "## Add orchestration deployment URL to variables.py \n",
    "üëÄ  Before we can started, one final step is missing. You need to change the value assigened to the **AICORE_ORCHESTRATION_DEPLOYMENT_URL** in the ```variables.py``` to your own orchestration deployment URL.\n",
    "Therefore run the blow code and copy the URL and add into the variables.py add the respective place.\n",
    "<p>\n",
    "<img src=\"images/deployment_url.png\" alt=\"Visual Studio Code\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "![Deployment URL screenshot](images/deployment_url.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import helpers\n",
    "\n",
    "\n",
    "init_env.set_environment_variables()\n",
    "\n",
    "url = helpers.extract_deployment_url()\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd8a9e",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Restart the Juypyter Kernel\n",
    "\n",
    "<p>\n",
    "<img src=\"images/restart_kernel.png\" alt=\"Visual Studio Code\" width=\"800\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34dd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "# Run this to test whether all environment variables are set correctly \n",
    "init_env.set_environment_variables()\n",
    "\n",
    "assert variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL!='', \"\"\"You should change the value assigned to the `AICORE_ORCHESTRATION_DEPLOYMENT_URL` in the `variables.py` file to your own resource group first!\"\"\"\n",
    "print(f\"Deployment URL is set to: {variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0fbf8",
   "metadata": {},
   "source": [
    "> \n",
    "> ‚ú® **More information: Orchestration Service**  \n",
    "> \n",
    ">The orchestration service of Generative AI Hub lets you use all the available models with the same codebase. You only deploy the orchestration service and then you can access all available models simply by changing the model name parameter.   \n",
    ">You can also use grounding, prompt templating, data masking and content filtering capabilities.  \n",
    ">In the following we are mainly using it for grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee4502",
   "metadata": {},
   "source": [
    "## Let's start with a simple prompt\n",
    "\n",
    "To understand the general idea about grounding a model, let us first start with the simple prompt without grounding it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37cf8a",
   "metadata": {},
   "source": [
    "### Import the packages we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c55109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d1b15",
   "metadata": {},
   "source": [
    "### Assign the model we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    name=\"gemini-2.5-flash\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94265bc",
   "metadata": {},
   "source": [
    "### Create a prompt Template\n",
    "The parameter user_query in the code snippet below is going to hold the user query that you will add later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "                UserMessage(\"\"\"Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe68a1",
   "metadata": {},
   "source": [
    "### Create an orchestration configuration\n",
    "Next you need to create the orchestration configuration by including the LLM we referencesd and the prompt template we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6240964",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da235d",
   "metadata": {},
   "source": [
    "### Execute the query\n",
    "This configuration we now add to the OrchestrationService and then we run to retrieve the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config,\n",
    ")\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"user_query\",\n",
    "            #TODO Here you can change the user prompt into whatever you want to ask the model\n",
    "            value=\"What is Joule?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b4a52",
   "metadata": {},
   "source": [
    "### Looks correct, but not for our context\n",
    "\n",
    "The model‚Äôs answer to ‚ÄúWhat is Joule?‚Äù is *technically* correct because, without any extra context, it defaults to the statistically most common public meaning (the physics unit of energy). Our expectation at SAP TechEd was an SAP‚Äëspecific interpretation (e.g., an SAP capability or product named ‚ÄúJoule‚Äù), but the prompt contained no SAP signals, product names, or retrieved SAP documents to steer the model. With no domain clues, the generic global prior wins.  \n",
    "\n",
    "Grounding can solve this: attach a grounding/data-retrieval step (SAP Help, internal docs, knowledge base) and inject them into the prompt (or pipeline) before generation. \n",
    "In short: no context ‚Üí generic answer; grounded context ‚Üí domain‚Äëspecific answer.\n",
    "\n",
    "üí™  Let's do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8fcb3",
   "metadata": {},
   "source": [
    "## Ground your prompt with SAP Help\n",
    "\n",
    "To add context to the retrieval step we need to some change to our original steps. \n",
    "\n",
    "Starting at the template by adding to the UserMessage ```Context:{{ ?grounding_response }}```. Whereas **grounding_response** is the context retrieved from the context information, in this case sap.help.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "                UserMessage(\"\"\"Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                Context:{{ ?grounding_response }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a46eb",
   "metadata": {},
   "source": [
    "### Import the packages we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab322589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGroundingFilter\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingModule\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingType\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGrounding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f212319",
   "metadata": {},
   "source": [
    "### Define data repository \n",
    "We need to configure the Grounding Module, where we first define the data repository that we want to use via the **filter** parameter. \n",
    "  \n",
    "‚û°Ô∏è Add **\"help.sap.com\"** as the **data_repository_type** and run the statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = [\n",
    "            DocumentGroundingFilter(id=\"SAPHelp\", data_repository_type=<data_repository_type>) # replace <data_repository_type> by \"help.sap.com\"\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c16e5",
   "metadata": {},
   "source": [
    "### Create Grounding Configuration\n",
    "Next we create the grounding configuration by using **GroundingModule** for managing and applying grounding configurations:  \n",
    "- **type**: \"document_grounding_service\"\n",
    "- **config**:  Configuration dictionary including parameter defined in the template and filter that includes the data repository type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d9cc4",
   "metadata": {},
   "source": [
    "### Create Orchestration Configuration \n",
    "\n",
    "Grounding configuration ```grounding_config``` is now an addidional parameter that we add to the Orchestration configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74948dc3",
   "metadata": {},
   "source": [
    "### Execute the  Query\n",
    "Configuration will be added again to the OrchestrationService and then we run to retrieve the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57564d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue( \n",
    "            name=\"user_query\",\n",
    "            value=\"What is Joule?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e18b87",
   "metadata": {},
   "source": [
    "### The right context\n",
    "Grounding succeeded: with help.sap.com context injected, the model produced the correct SAP‚Äëspecific answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90482d6",
   "metadata": {},
   "source": [
    "## Summary \n",
    "You learned the basic grounding concepts in SAP AI Core and how you to use it improve the retrieval.\n",
    "\n",
    "In the next execercise you will learn on how to injest custom documents. \n",
    "\n",
    "\n",
    "Continue to - [Excercise 3: Ground your LLM with custom documents](ex3-1-grounding-vector-api.md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai167env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
