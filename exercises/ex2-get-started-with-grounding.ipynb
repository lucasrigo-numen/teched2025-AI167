{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5001f602",
   "metadata": {},
   "source": [
    "# Exercise 2 - Get Started with Grounding\n",
    "\n",
    "In this exercise, we'll start exploring the grounding on SAP AI Core. Grounding allows Large Language Models (LLMs) to reference specific knowledge sources when generating responses, which can help improve accuracy and relevance. \n",
    "\n",
    "We'll start with the basics by grounding an LLM using SAP.help as our knowledge source. \n",
    "\n",
    "This exercise will cover:\n",
    "\n",
    "* Basic grounding concepts in SAP AI Core\n",
    "* How to set up grounding with a sap.help.com\n",
    "* Comparing responses with and without grounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306eb73",
   "metadata": {},
   "source": [
    "## Check your connection to AI Core \n",
    "üëÄ  In the ```TECHE2025-167/excercise/init_env.py``` the values from ```TECHED2025-AI167/.aicore-config.json``` are assigned to environmental variables. That way the **SAP Cloud SDK for AI(Python)** will connect to AI Core. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a76e6",
   "metadata": {},
   "source": [
    "## Orchestration Service and Resource Group\n",
    "Before we get into the exercise some information upfront. \n",
    "The grounding service we are going to use is available via the **Orchestration Service on GenAI Hub**. The Orchestration service lets you use all the available models with the same codebase. Once orchestration service is deployed you can access all available models simply by changing the model name parameter. Besides grounding you can also use prompt templating, data masking and content filtering capabilities. \n",
    "\n",
    "Besides having the orchestration service up and running in your resource group, you also have to make the resource group available to the grounding service.\n",
    "\n",
    "Good news upfront: We already took care of it!\n",
    "\n",
    "Let us check whether both is set properly in our environment variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34dd979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment URL extraction response data: {'count': 3, 'resources': [{'id': 'd8b26e53441b6143', 'createdAt': '2026-01-09T18:50:38Z', 'modifiedAt': '2026-01-09T18:50:38Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}, 'backend_details': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'latestRunningConfigurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-09T18:50:52Z', 'startTime': '2026-01-09T18:51:57Z', 'configurationName': 'gemini-2.5-flash_autogenerated', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d8b26e53441b6143'}, {'id': 'da9d1c13b14cc370', 'createdAt': '2026-01-08T21:11:13Z', 'modifiedAt': '2026-01-08T21:11:13Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}, 'backend_details': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'latestRunningConfigurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-08T21:11:53Z', 'startTime': '2026-01-08T21:13:10Z', 'configurationName': 'cline', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/da9d1c13b14cc370'}, {'id': 'd5a5f3118e21d6bf', 'createdAt': '2025-12-30T19:26:12Z', 'modifiedAt': '2025-12-30T19:26:12Z', 'status': 'RUNNING', 'details': {'scaling': {'backendDetails': {}, 'backend_details': {}}, 'resources': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'orchestration', 'configurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'latestRunningConfigurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2025-12-30T19:26:40Z', 'startTime': '2025-12-30T19:27:55Z', 'configurationName': 'defaultOrchestrationConfig', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf'}]}\n",
      "Found deployment URL: https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf\n",
      "Resource Group is set to: default\n",
      "Orchestration Deployment URL is set to: https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf\n"
     ]
    }
   ],
   "source": [
    "import init_env\n",
    "import variables\n",
    "import os\n",
    "\n",
    "init_env.set_environment_variables()\n",
    "\n",
    "print(f\"Resource Group is set to: {os.getenv('AICORE_RESOURCE_GROUP')}\")\n",
    "print(f\"Orchestration Deployment URL is set to: {variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee4502",
   "metadata": {},
   "source": [
    "## Let's start with a simple prompt\n",
    "\n",
    "To understand the general idea about grounding a model, let us first start with the simple prompt without grounding it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37cf8a",
   "metadata": {},
   "source": [
    "### Import the packages we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c55109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d1b15",
   "metadata": {},
   "source": [
    "### Assign the model we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6140cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    name=\"gemini-2.5-flash\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")\n",
    "print(\"LLM initialized:\", llm.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94265bc",
   "metadata": {},
   "source": [
    "### Create a prompt Template\n",
    "The parameter user_query in the code snippet below is going to hold the user query that you will add later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eade6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"You are a helpful assistant.\"),\n",
    "                UserMessage(\"\"\"Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe68a1",
   "metadata": {},
   "source": [
    "### Create an orchestration configuration\n",
    "Next you need to create the orchestration configuration by including the LLM we referenced and the prompt template we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6240964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrchestrationConfig gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")\n",
    "print(\"OrchestrationConfig\", config.llm.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da235d",
   "metadata": {},
   "source": [
    "### Execute the query\n",
    "This configuration we now add to the OrchestrationService and then we run to retrieve the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a402f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment URL extraction response data: {'count': 3, 'resources': [{'id': 'd8b26e53441b6143', 'createdAt': '2026-01-09T18:50:38Z', 'modifiedAt': '2026-01-09T18:50:38Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}, 'backend_details': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'latestRunningConfigurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-09T18:50:52Z', 'startTime': '2026-01-09T18:51:57Z', 'configurationName': 'gemini-2.5-flash_autogenerated', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d8b26e53441b6143'}, {'id': 'da9d1c13b14cc370', 'createdAt': '2026-01-08T21:11:13Z', 'modifiedAt': '2026-01-08T21:11:13Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}, 'backend_details': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'latestRunningConfigurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-08T21:11:53Z', 'startTime': '2026-01-08T21:13:10Z', 'configurationName': 'cline', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/da9d1c13b14cc370'}, {'id': 'd5a5f3118e21d6bf', 'createdAt': '2025-12-30T19:26:12Z', 'modifiedAt': '2025-12-30T19:26:12Z', 'status': 'RUNNING', 'details': {'scaling': {'backendDetails': {}, 'backend_details': {}}, 'resources': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'orchestration', 'configurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'latestRunningConfigurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2025-12-30T19:26:40Z', 'startTime': '2025-12-30T19:27:55Z', 'configurationName': 'defaultOrchestrationConfig', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf'}]}\n",
      "Found deployment URL: https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf\n",
      "OrchestrationService initialized with API URL: https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf gemini-2.5-flash\n",
      "The **Joule (symbol: J)** is the **SI unit of energy, work, and heat**.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "1.  **Unit of Energy:** It quantifies the amount of energy transferred or expended. Whether it's mechanical energy, electrical energy, thermal energy, or chemical energy, the Joule is the standard unit for measuring it.\n",
      "\n",
      "2.  **Named After:** It is named after the English physicist **James Prescott Joule** (1818‚Äì1889), who made significant contributions to the understanding of heat and its relationship to mechanical work.\n",
      "\n",
      "3.  **Mathematical Definition:**\n",
      "    *   **Work:** One Joule is defined as the amount of work done when a force of one **Newton (N)** displaces an object by one **meter (m)** in the direction of the force.\n",
      "        *   Therefore, **1 J = 1 N¬∑m** (Newton-meter).\n",
      "    *   **Power and Time:** It can also be defined as the energy dissipated as heat when an electric current of one ampere (A) passes through a resistance of one ohm (Œ©) for one second (s), or more simply, **one watt-second (W¬∑s)**.\n",
      "        *   Therefore, **1 J = 1 W¬∑s**.\n",
      "\n",
      "4.  **Magnitude and Usage:**\n",
      "    *   The Joule is a relatively small unit of energy. For everyday energy measurements, larger units like **kilojoules (kJ = 1000 J)** or **megajoules (MJ = 1,000,000 J)** are often used.\n",
      "    *   It's used across all branches of science and engineering, from physics and chemistry to biology and engineering.\n",
      "\n",
      "**Examples to understand the scale of a Joule:**\n",
      "\n",
      "*   **Lifting an apple:** Lifting a small apple (about 100g) by 1 meter requires approximately **1 Joule** of energy.\n",
      "*   **Heat:** The amount of heat required to raise the temperature of 1 gram of water by about 0.24 degrees Celsius is roughly **1 Joule**.\n",
      "*   **Power:** A 100-watt light bulb consumes **100 Joules** of energy every second.\n",
      "\n",
      "In essence, the Joule is the fundamental way we measure \"how much energy\" is involved in any process.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config,\n",
    ")\n",
    "print(\"OrchestrationService initialized with API URL:\", orchestration_service.api_url, config.llm.name)\n",
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"user_query\",\n",
    "            value=\"What is Joule?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b4a52",
   "metadata": {},
   "source": [
    "### Looks correct, but not for our context\n",
    "\n",
    "The model‚Äôs answer to ‚ÄúWhat is Joule?‚Äù is *technically* correct because, without any extra context, it defaults to the statistically most common public meaning (the physics unit of energy). Our expectation at SAP TechEd was an SAP‚Äëspecific interpretation (e.g., an SAP capability or product named ‚ÄúJoule‚Äù), but the prompt contained no SAP signals, product names, or retrieved SAP documents to steer the model. With no domain clues, the generic global prior wins.  \n",
    "\n",
    "Grounding can solve this: attach a grounding/data-retrieval step (SAP Help, internal docs, knowledge base) and inject them into the prompt (or pipeline) before generation. \n",
    "In short: no context ‚Üí generic answer; grounded context ‚Üí domain‚Äëspecific answer.\n",
    "\n",
    "üí™  Let's do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8fcb3",
   "metadata": {},
   "source": [
    "## Ground your prompt with SAP Help\n",
    "\n",
    "To add context to the retrieval step we need to some change to our original steps. \n",
    "\n",
    "Starting at the template by adding to the UserMessage ```Context:{{ ?grounding_response }}```. Whereas **grounding_response** is the context retrieved from the context information, in this case sap.help.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf17b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"You are a helpful assistant.\"),\n",
    "                UserMessage(\"\"\"Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                Context:{{ ?grounding_response }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a46eb",
   "metadata": {},
   "source": [
    "### Import the packages we want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab322589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGroundingFilter\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingModule\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingType\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGrounding\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DataRepositoryType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f212319",
   "metadata": {},
   "source": [
    "### Define data repository \n",
    "We need to configure the Grounding Module, where we first define the data repository that we want to use via the **filter** parameter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cee90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = [\n",
    "            DocumentGroundingFilter(    id=\"SAPHelp\",\n",
    "                                        data_repository_type=DataRepositoryType.URL.value)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c16e5",
   "metadata": {},
   "source": [
    "### Create Grounding Configuration\n",
    "Next we create the grounding configuration by using **GroundingModule** for managing and applying grounding configurations:  \n",
    "- **type**: \"document_grounding_service\"\n",
    "- **config**:  Configuration dictionary including parameter defined in the template and filter that includes the data repository type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8cfdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d9cc4",
   "metadata": {},
   "source": [
    "### Create Orchestration Configuration \n",
    "\n",
    "Grounding configuration ```grounding_config``` is now an additional parameter that we add to the Orchestration configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e9e82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74948dc3",
   "metadata": {},
   "source": [
    "### Execute the  Query\n",
    "Configuration will be added again to the OrchestrationService and then we run to retrieve the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57564d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment URL extraction response data: {'count': 3, 'resources': [{'id': 'd8b26e53441b6143', 'createdAt': '2026-01-09T18:50:38Z', 'modifiedAt': '2026-01-09T18:50:38Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}, 'backend_details': {'model': {'name': 'gemini-2.5-flash', 'version': '001'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'latestRunningConfigurationId': '2757402c-d65b-4d6d-9fd8-3a7f8e300d19', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-09T18:50:52Z', 'startTime': '2026-01-09T18:51:57Z', 'configurationName': 'gemini-2.5-flash_autogenerated', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d8b26e53441b6143'}, {'id': 'da9d1c13b14cc370', 'createdAt': '2026-01-08T21:11:13Z', 'modifiedAt': '2026-01-08T21:11:13Z', 'status': 'RUNNING', 'details': {'resources': {'backendDetails': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}, 'backend_details': {'model': {'name': 'anthropic--claude-4-sonnet', 'version': 'latest'}}}, 'scaling': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'foundation-models', 'configurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'latestRunningConfigurationId': 'a0e3ca46-7a2c-4a20-91ec-3de4802ced72', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2026-01-08T21:11:53Z', 'startTime': '2026-01-08T21:13:10Z', 'configurationName': 'cline', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/da9d1c13b14cc370'}, {'id': 'd5a5f3118e21d6bf', 'createdAt': '2025-12-30T19:26:12Z', 'modifiedAt': '2025-12-30T19:26:12Z', 'status': 'RUNNING', 'details': {'scaling': {'backendDetails': {}, 'backend_details': {}}, 'resources': {'backendDetails': {}, 'backend_details': {}}}, 'scenarioId': 'orchestration', 'configurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'latestRunningConfigurationId': '96b16ab1-acb6-454d-a6e7-d231f49c18c6', 'lastOperation': 'CREATE', 'targetStatus': 'RUNNING', 'submissionTime': '2025-12-30T19:26:40Z', 'startTime': '2025-12-30T19:27:55Z', 'configurationName': 'defaultOrchestrationConfig', 'deploymentUrl': 'https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf'}]}\n",
      "Found deployment URL: https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d5a5f3118e21d6bf\n",
      "Based on the provided context, Joule is:\n",
      "\n",
      "**SAP's generative AI copilot** designed to revolutionize how users interact with their SAP business systems.\n",
      "\n",
      "Here's a more detailed breakdown of what Joule is and what it does:\n",
      "\n",
      "*   **AI Copilot for Business:** It acts as an intelligent assistant that truly understands your business context, making every interaction with SAP systems simpler and more efficient.\n",
      "*   **Conversational Interface:** Joule enables natural language interactions between humans and computers, allowing users to ask questions, give commands, and automate tasks using plain language.\n",
      "*   **Simplifies Tasks & Automates Processes:** It streamlines workflows, helps complete tasks, directs users to the right applications, and finds information quickly, thereby improving both employee and customer satisfaction.\n",
      "*   **Integrated Across SAP Ecosystem:** Joule is a unified experience across SAP's solution portfolio, guiding users through content discovery and providing role-based access to relevant processes from anywhere. It integrates with applications like SAP S/4HANA Cloud Public Edition, SAP Mobile Start, SAP Concur Expense, SAP LeanIX, and SAP Datasphere.\n",
      "*   **Key Capabilities:**\n",
      "    *   **Information & Insights:** Provides quick answers, smart insights, and conversational access to product documentation (e.g., SAP Help Portal).\n",
      "    *   **Task Automation:** Helps process billing documents, update delivery dates, manage expense reports, and create to-dos.\n",
      "    *   **Navigation & Discovery:** Directs users to applications, searches for diagrams, reports, and fact sheets within SAP LeanIX.\n",
      "    *   **Contextual Understanding:** Uses \"document grounding\" to add context from uploaded documents and leverages large language models to summarize search results.\n",
      "    *   **Multi-Language Support:** Supports multiple languages, automatically adopting the language configured in the SAP application.\n",
      "*   **Technical Foundation:** It runs as a multi-tenant application on SAP BTP Cloud Foundry, features a rich web client with SAP Fiori compliant UI controls, and is designed to be enterprise-ready, adhering to AI ethics and GDPR.\n",
      "*   **Business Benefits:** Leads to faster work, smarter insights for quicker decision-making, better outcomes (e.g., for job descriptions, coding assistance), and full control over decision-making and data privacy in a secure environment.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"user_query\",\n",
    "            value=\"What is Joule?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e18b87",
   "metadata": {},
   "source": [
    "### The right context\n",
    "Grounding succeeded: with help.sap.com context injected, the model produced the correct SAP‚Äëspecific answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90482d6",
   "metadata": {},
   "source": [
    "## Summary \n",
    "You learned the basic grounding concepts in SAP AI Core and how you to use it improve the retrieval.\n",
    "\n",
    "In the next exercise you will learn on how to ingest custom documents. Therefore we go back to github repo. \n",
    "\n",
    "Continue to - [Exercise 3: Ground your LLM with custom documents](https://github.com/SAP-samples/teched2025-AI167/blob/main/exercises/ex3-1-grounding-vector-api.md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai167env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
