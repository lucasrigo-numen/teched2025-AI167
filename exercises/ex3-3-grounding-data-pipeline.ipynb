{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb7263b",
   "metadata": {},
   "source": [
    "# Exercise 3.3: Run data pipeline to vectorize documents\n",
    "\n",
    "Instead of doing all the steps by yourself, as it was shown in the previous exercise, you can also leverage the pipeline API.\n",
    "\n",
    "The pipeline collects documents and segments the data into chunks. It generates embeddings, which are multidimensional representations of textual information, and stores them efficiently in the vector database.\n",
    "\n",
    "In this Exercise you will do the following steps:\n",
    "* Perform initial one time admin tasks: Create a generic secret \n",
    "* Prepare Vector knowledge Base: Configure Pipeline API to read files from the object store and store it in the vector database. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930e3c4",
   "metadata": {},
   "source": [
    "## Create a generic secret for Object Store \n",
    "\n",
    "We first must create a generic secret at the resource group level. Secrets are a means of allowing and controlling connections across directions and tools, without compromising your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b386e",
   "metadata": {},
   "source": [
    "To create the generic secrets we will send the POST with URL {{apiurl}}/v2/admin/secrets. \n",
    "\n",
    "**Note**: \n",
    "* Every value in the *data* dictionary needs to be base64-encoded. \n",
    "* labels need to contain key-value pair *\"ext.ai.sap.com/document-grounding\"* and *\"ext.ai.sap.com/documentRepositoryType\"* with value S3. This is needed to enable grounding and declare S3 as the repository source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def b64(val):\n",
    "     return base64.b64encode(val.encode(\"utf-8\")).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def secret_dict():\n",
    "        return {\n",
    "            'name': 'aws3-secret-3',\n",
    "            'data': {\n",
    "            \"url\": b64(\"https://s3-eu-central-1.amazonaws.com\"),\n",
    "            \"authentication\": b64(\"NoAuthentication\"),\n",
    "            \"description\": b64(\"For Grounding\"),\n",
    "            \"access_key_id\": b64(os.environ[\"ACCESS_KEY_ID\"]),\n",
    "            \"bucket\": b64(os.environ[\"BUCKET\"]),\n",
    "            \"host\": b64(\"s3-eu-central-1.amazonaws.com\"),\n",
    "            \"region\": b64(\"eu-central-1\"), \n",
    "            \"secret_access_key\": b64(os.environ[\"SECRET\"]),\n",
    "            \"username\": b64(os.environ[\"USER\"])            \n",
    "            },\n",
    "            \"labels\": [\n",
    "                {\n",
    "                    \"key\": \"ext.ai.sap.com/document-grounding\",\n",
    "                    \"value\": \"true\"\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"ext.ai.sap.com/documentRepositoryType\",\n",
    "                    \"value\": \"S3\"\n",
    "                }\n",
    "         ]\n",
    "        }\n",
    "\n",
    "body = {\n",
    "    'name': secret_dict()['name'],\n",
    "    'data': secret_dict()['data'],\n",
    "    'labels': secret_dict()['labels']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "\n",
    "client = AICoreV2Client (base_url=os.environ[\"AICORE_BASE_URL\"]+'/v2',\n",
    "                         auth_url= os.environ[\"AICORE_AUTH_URL\"],\n",
    "                         client_id=os.environ[\"AICORE_CLIENT_ID\"],\n",
    "                         client_secret=os.environ[\"AICORE_CLIENT_SECRET\"],\n",
    "                         resource_group=os.environ[\"AICORE_RESOURCE_GROUP\"]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ababc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response_dict = requests.post(\n",
    "        url=f\"{client.rest_client.base_url}/admin/secrets\", \n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"AI-Tenant-Scope\": \"false\",\n",
    "            \"Authorization\": client.rest_client.get_token(),\n",
    "            \"AI-Resource-Group\": os.environ[\"AICORE_RESOURCE_GROUP\"]\n",
    "        },\n",
    "        json=body\n",
    "    )\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf046922",
   "metadata": {},
   "source": [
    "## Create Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c62dd",
   "metadata": {},
   "source": [
    "### Import the packages we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from gen_ai_hub.document_grounding.client import PipelineAPIClient\n",
    "from gen_ai_hub.document_grounding.models.pipeline import S3PipelineCreateRequest, CommonConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "aicore_client = get_proxy_client();\n",
    "pipeline_api_client = PipelineAPIClient(aicore_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e230be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generic_secret_s3_bucket = \"aws3-secret-3\"\n",
    "s3_config = S3PipelineCreateRequest(configuration= CommonConfiguration(destination=generic_secret_s3_bucket))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = pipeline_api_client.create_pipeline(s3_config)\n",
    "print(f\"Reference the Vector knowledge base using the pipeline ID: {response.pipelineId}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the status of the vectorization pipeline until it is completed\n",
    "print(pipeline_api_client.get_pipeline_status(response.pipelineId))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed0961",
   "metadata": {},
   "source": [
    "Once the status switched to ```'FINISHED'``` the vectorization is completed and we can continue with the next steps. Our PDF is vectorized and stored in the HANA Vector Store. \n",
    "\n",
    "If you want to see all pipelines you can run ```get_pipelines()``` this will list all the pipelines in your resource group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipelines = pipeline_api_client.get_pipelines()\n",
    "\n",
    "print(pipelines.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbc9c7",
   "metadata": {},
   "source": [
    "üéâ Congratulations you successfully created you first data repository via the pipeline API .üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9cccf4",
   "metadata": {},
   "source": [
    "## Use the data repository to ground the response\n",
    "Now let us use this data repository to generate more accurate responses. We will use again the Orchestration Services as we did in Exercise 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135cb3b",
   "metadata": {},
   "source": [
    "### Assign the model you want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd89194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gemini-2.5-flash\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d74e69",
   "metadata": {},
   "source": [
    "### Create a prompt Template\n",
    "\n",
    "This time we would like to question answered that are related to SAP TechEd 2025 and the mascot Kasimir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a44414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.template import Template\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "\n",
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"You are a helpful SAP TechEd assistant.\"),\n",
    "                UserMessage(\"\"\"Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                Context:{{ ?grounding_response }}\n",
    "                \"\"\")\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315636ff",
   "metadata": {},
   "source": [
    "### List all data repositories\n",
    "\n",
    "For the next step to define the data repository that we want to use to ground the response, we need to get the respective id.   \n",
    "Let us list all data repositories that we have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94219eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.document_grounding.client import RetrievalAPIClient\n",
    "retrieval_api_client = RetrievalAPIClient(aicore_client)\n",
    "\n",
    "repos = retrieval_api_client.get_data_repositories()\n",
    "\n",
    "print(repos.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979b924",
   "metadata": {},
   "source": [
    "Overall you should see three data repositories: SAP Help, Kasimir (created in Exercise 3.1 via Vector API) and the data repository that we just created via the pipeline ( the name title is something like \"pipeline-...\")\n",
    "\n",
    "‚û°Ô∏è Copy the ```id``` as we need it for the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678d986",
   "metadata": {},
   "source": [
    "### Define the data repository\n",
    "We need again to configure the Grounding Module, where we add the data repository that we want to use via the **filter** parameter. \n",
    "\n",
    "‚û°Ô∏è Replace ```<id>``` in **data_repository** array by the data repository id created in the previous step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac638e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGroundingFilter\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DataRepositoryType\n",
    "filters = [\n",
    "            DocumentGroundingFilter(    id=\"KasimirTechEd2025\", \n",
    "                                        data_repository_type= DataRepositoryType.VECTOR.value,\n",
    "                                        data_repositories=[\"cc04bf07-0666-4f07-8398-cf6df8c1bf69\"])\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d03f69",
   "metadata": {},
   "source": [
    "### Create Grounding Configuration\n",
    "Next we create the grounding configuration by using **GroundingModule** for managing and applying grounding configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd23722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingModule\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingType\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGrounding\n",
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4b440",
   "metadata": {},
   "source": [
    "### Create orchestration configuration including Grounding Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59768f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681498e",
   "metadata": {},
   "source": [
    "### Execute the  Query\n",
    "Configuration will be added again to the OrchestrationService and then we run to retrieve the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import variables\n",
    "from gen_ai_hub.orchestration.models.template import TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue( \n",
    "            name=\"user_query\",\n",
    "            value=\"What will be the evening event at SAP TechEd?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9ad25",
   "metadata": {},
   "source": [
    "Nice, this band we do not want to miss. \n",
    "\n",
    "However let us ask another question. What about dogs, are dogs allowed at SAP TechED ?    \n",
    "Let us run the next query: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue( \n",
    "            name=\"user_query\",\n",
    "            value=\"Are dogs allowed at SAP TechEd?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98341807",
   "metadata": {},
   "source": [
    "The answer is valid, given the data repository we use to ground the response. However while we embedded **Kasimirs TechEd Policy** in Exercise 3.1 via Vector API, there was at least one chunk that stated, that at least one dog is allowed at TechEd : Bruno!   \n",
    "However this answer can currently not retrieved as we are currently not using **Kasimirs TechEd Policy** data repository to ground the response.    \n",
    "\n",
    "Let us change this by adding this as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1244183",
   "metadata": {},
   "source": [
    "### List again all Data Repositories\n",
    "First we need to get the id.    \n",
    "Therefore we list again all the data repos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042011ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.document_grounding.client import RetrievalAPIClient\n",
    "retrieval_api_client = RetrievalAPIClient()\n",
    "\n",
    "repos = retrieval_api_client.get_data_repositories()\n",
    "\n",
    "print(repos.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf91af4",
   "metadata": {},
   "source": [
    "‚¨ÜÔ∏è Copy the ```id``` of the resource that as **title = Kasimir.**\n",
    "\n",
    "### Define the data repository\n",
    "We need again to configure the Grounding Module, where we add the data repository that we want to use via the **filter** parameter. \n",
    "\n",
    "‚¨áÔ∏è Add this ```id ```to data_repository list in the code below.    \n",
    "It should look similar to the following code snippet (except the ids are different): ``` data_repositories=[\"cc04bf07-0666-4f07-8398-cf6df8c1bf69\", \"0a2c7d76-f1a0-462c-b351-7d5e87db9fe3\"]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = [\n",
    "            DocumentGroundingFilter(    id=\"KasimirTechEd2025\", \n",
    "                                        data_repository_type= DataRepositoryType.VECTOR.value,\n",
    "                                        data_repositories=[\"cc04bf07-0666-4f07-8398-cf6df8c1bf69\", \"0a2c7d76-f1a0-462c-b351-7d5e87db9fe3\"])\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e50a30",
   "metadata": {},
   "source": [
    "### Create Grounding Configuration\n",
    "Next we create the grounding configuration by using **GroundingModule** for managing and applying grounding configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingModule\n",
    "from gen_ai_hub.orchestration.models.document_grounding import GroundingType\n",
    "from gen_ai_hub.orchestration.models.document_grounding import DocumentGrounding\n",
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388068e",
   "metadata": {},
   "source": [
    "### Create orchestration configuration including Grounding Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4dbf5",
   "metadata": {},
   "source": [
    "### Execute the  Query\n",
    "Configuration will be added again to the OrchestrationService and then we run to retrieve the answer.\n",
    "\n",
    "Let's check whether the response changes towards whether really not dogs are allowed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88740f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import variables\n",
    "from gen_ai_hub.orchestration.models.template import TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue( \n",
    "            name=\"user_query\",\n",
    "            value=\"Are dogs allowed at SAP TechEd?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73d6a8",
   "metadata": {},
   "source": [
    "Awesome, now also the TechEd policy will considered in grounding our response.    \n",
    "\n",
    "üéâ Congratulations! You successfully mastered to add two data repositories to your Grounding Module to ground your response  .üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ad54f",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "üéâ And that's a wrap! .üéâ\n",
    "\n",
    "Today you learned how to ground an LLM using Grounding in GenAIHub, created your own vector-based data repository via Vector API, processed documents with the Pipeline API, retrieved knowledge via the Retrieval API, and orchestrated everything end-to-end.\n",
    "Grounding brings AI from impressive to reliable, and with these tools, you now have the foundation to build enterprise-grade, trustworthy AI solutions with your own data.\n",
    "I hope this session sparked new ideas and confidence ‚Äî and that you leave ready to turn your real-world knowledge into real AI impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5164f48",
   "metadata": {},
   "source": [
    "## Bonus: Postprocessing search results with the Cohere 3.5 Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc874a1",
   "metadata": {},
   "source": [
    "We have now seen that content can be brought into Document Grounding in different ways. When we add more content, it can become increasingly hard to surface the relevant information, especially if we need to query across different repositories.\n",
    "\n",
    "In this year's SAP TechEd, we are very happy to introduce you to a new feature in Document Grounding: post-processing for result sets, with the first application being the introduction of the [Cohere 3.5 reranking model](https://cohere.com/rerank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.document_grounding.client import RetrievalAPIClient\n",
    "\n",
    "retrieval_client = RetrievalAPIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec8e7c",
   "metadata": {},
   "source": [
    "Let's start by creating some filters.\n",
    "\n",
    "In the first filter, we will focus on documents ingested from PDF files. If you look closely, you will also see one new field in the API payload below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = {\n",
    "    \"id\": \"filter-1\",\n",
    "    \"searchConfiguration\": {\"maxChunkCount\": 5},\n",
    "    \"dataRepositories\": [\"*\"],\n",
    "    \"dataRepositoryType\": \"vector\",\n",
    "    \"filter\": {\n",
    "        \"operator\": \"or\",\n",
    "        \"left\": {\n",
    "            \"key\": \"fileSuffix\",\n",
    "            \"value\": [\".pdf\"],\n",
    "            \"scope\": \"document\",\n",
    "        },\n",
    "        \"right\": {\n",
    "            \"key\": \"mimeType\",\n",
    "            \"value\": [\"application/pdf\"],\n",
    "            \"scope\": \"document\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695a77d",
   "metadata": {},
   "source": [
    "In the second filter, we reference the custom metadata which we added in exercise 3-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b055715",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2 = {\n",
    "    \"id\": \"filter-2\",\n",
    "    \"searchConfiguration\": {\"maxChunkCount\": 5},\n",
    "    \"dataRepositories\": [\"*\"],\n",
    "    \"dataRepositoryType\": \"vector\",\n",
    "    \"filter\": {\n",
    "        \"key\": \"purpose\",\n",
    "        \"value\": [\"Kasimirs TechEd Cat Policy\"],\n",
    "        \"scope\": \"document\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f637e",
   "metadata": {},
   "source": [
    "By the way, the new API field mentioned above is the `filter` key. This recently introduced field enables complex boolean filters on document metadata - later to be extended to include also collection and chunk metadata.\n",
    "\n",
    "Note that this is independent of the postprocessing feature, but rather an enhanced filtering capability for retrieval in the vector API which is accesssed here via the retrieval API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5d7a1",
   "metadata": {},
   "source": [
    "Finally, we also craft a filter to pull in content from the SAP Help Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_3 = {\n",
    "    \"id\": \"filter-3\",\n",
    "        \"searchConfiguration\": {\"maxChunkCount\": 10},\n",
    "        \"dataRepositories\": [\"*\"],\n",
    "        \"dataRepositoryType\": \"help.sap.com\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d09b9b",
   "metadata": {},
   "source": [
    "We can send all three filters to the retrieval API in one request, and we will get back three individual result sets.\n",
    "\n",
    "While this is practical for some use cases, we sometimes just want to most relevant results overall.\n",
    "\n",
    "Below, we assemble the final search request from the three filters.\n",
    "\n",
    "Additionally, we include the newly introduced `postProcessing` key, where we instruct the reranker to gives us the 10 most relevant chunks from the output of the three filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Responsible AI for cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_input_postprocessing = {\n",
    "    \"query\": query,\n",
    "    \"filters\": [\n",
    "        filter_1,\n",
    "        filter_2,\n",
    "        filter_3,\n",
    "    ],\n",
    "    \"postProcessing\": [\n",
    "        {\n",
    "            \"id\": \"post-processing-1\",\n",
    "            \"inputs\": [\n",
    "                {\"id\": \"filter-1\"},\n",
    "                {\"id\": \"filter-2\"},\n",
    "                {\"id\": \"filter-3\"},\n",
    "            ],\n",
    "            \"maxChunkCount\": 10,\n",
    "            \"strategy\": {\n",
    "                \"type\": \"reranker\",\n",
    "                \"model\": \"cohere-3.5\",\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_client.rest_client.post(path=f\"{retrieval_client.path}/search\", body=search_input_postprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to inspect the entire response!\n",
    "# import json # For pretty-printing\n",
    "# print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # For pretty-printing\n",
    "\n",
    "post_processing_result = None\n",
    "\n",
    "for result_set in response['results']:\n",
    "    if  result_set['filter_id'] == \"post-processing-1\":\n",
    "        post_processing_result = result_set\n",
    "\n",
    "if post_processing_result is None:\n",
    "    print(\"Oops, no post-processing results found - check your code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_repository in post_processing_result[\"results\"]:\n",
    "    for document in data_repository[\"data_repository\"][\"documents\"]:\n",
    "        for chunk in document['chunks']:\n",
    "            print(chunk[\"content\"])\n",
    "            print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(post_processing_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1172da3",
   "metadata": {},
   "source": [
    "The results are still quite noisy, containing many irrelevant chunks - no surprise given that we asked for 10 chunks. We can further reduce the number of chunks by applying a client-side filter on the final post processing score.\n",
    "\n",
    "The relevant threshold must be carefully calibrated for each use case, and is also dependent on the reranker model use. See the Cohere [documentation on interpreting reranker results](https://docs.cohere.com/docs/reranking-best-practices#interpreting-results), which documents a possible process to determine the relevance threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ba0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold of 0.3 chosen based on superficial inspection of results :)\n",
    "threshold = 0.3\n",
    "\n",
    "for data_repository in post_processing_result[\"results\"]:\n",
    "    for document in data_repository[\"data_repository\"][\"documents\"]:\n",
    "        for chunk in document['chunks']:\n",
    "            if chunk['post_processing_score'][\"value\"] >= threshold:\n",
    "                print(\"Postprocessing Score:\", chunk['post_processing_score'][\"value\"])\n",
    "                print(chunk[\"content\"])\n",
    "                print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b35988",
   "metadata": {},
   "source": [
    "Stay tuned for postprocessing support in the orchestration service. For now, the postprocessing API can only be accessed directly via the retrieval API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai167env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
